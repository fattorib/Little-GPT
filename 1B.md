|----------|------:|--------|-----:|---|-----:|
|lambada   |      0|ppl     |9.7583|_  |0.2723|
|          |       |acc     |0.5265|_  |0.0070|

|hellaswag |      0|acc     |0.3336|_  |0.0047|
|          |       |acc_norm|0.3913|_  |0.0049|

|piqa      |      0|acc     |0.6931|_  |0.0108|
|          |       |acc_norm|0.6877|_  |0.0108|

|winogrande|      0|acc     |0.5217|_  |0.0140|



| Model        | LAMBADA (Acc) | LAMBADA (PPL) |   WikiText (PPL)  | Piqa (Acc) | Hellaswag (Acc) | Winogrande (Acc) | Training Tokens |
|--------------|:-------------:|:-------------:|:-----------------:|:----------:|:---------------:|:----------------:|:---------------:|
| **GPT-1B\*** | 52.65         | 9.758         | 23.052 (1024 CTX) | 69.31%     | 33.36%          | 52.17%           | 26B             |
| GPT-2 1.5B   | 51.21%        | 10.634        | 17.48 (1024 CTX)  | 70.78%     | 40.03%          | 59.40%           | -               |
| GPT-Neo 1.3B | 57.23         | 7.498         | 13.10 (2048 CTX)  | 71.11%     | 38.66           | 55.01            | 300B            |


| Model               | enwik8 (BPB) | text8 (BPC) | WikiText (PPL) |
|---------------------|--------------|:-----------:|:--------------:|
| GPT-1B\* (1024 ctx) | 1.134        | 1.174       | 23.052         |
| GPT-1B\* (2048 ctx) | 1.141        | 1.182       | 23.318         |


XL* 
0   benchmark/data/text8.gz    BPC  1.1744987                 1024
1   benchmark/data/text8.gz    BPC  1.1820451                 2048
0  benchmark/data/enwik8.gz    BPB  1.1347282                 1024
1  benchmark/data/enwik8.gz    BPB   1.141552                 2048
0         wikitext-2-raw-v1    PPL  23.052216                 1024
1         wikitext-2-raw-v1    PPL  23.318542                 2048


If all of these models were trained on shorter sequences, then how can we *accurately* benchmark them?

ALiBi works (mainly) by preventing the early token curse (this is just where early tokens in the context have a higher loss as they have less to predict on)

What are some options for a benchmark then?


